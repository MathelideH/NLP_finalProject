{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N87BWFCwQA-F"
   },
   "source": [
    "# **Spring 2023 NLP Final Project**\n",
    "\n",
    "- Mathelide Hou\n",
    "- Thanh Dang\n",
    "- Ryan Ruan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlxtbvkcHJon",
    "outputId": "41462e54-a765-426c-f25a-6d9979c65cc4"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "nltk.download('punkt')\n",
    "#Store data directory in a variable and only use this variable in your code\n",
    "dat_dir = './' \n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np\n",
    "from accelerate import Accelerator\n",
    "from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n",
    "from accelerate.utils import find_executable_batch_size\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2mkW1ibJ7hF",
    "outputId": "5d60874c-00b9-4c70-8c53-5913611340a1"
   },
   "outputs": [],
   "source": [
    "## Set \"device\" value depending on whether or not you have access to GPUs\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "accelerator = Accelerator()\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\",\n",
    "                                                            num_labels=3).to(device)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\",\n",
    "                                                      truncation=True,\n",
    "                                                      do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfxmsktEK2lO"
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# def load_data(dat_dir):                                 \n",
    "#     fnames = 'sarcasm.json'\n",
    "#     data = []\n",
    "#     train = []\n",
    "#     dev = []\n",
    "#     test = []\n",
    "#     df = pd.read_json(fnames, lines=True)\n",
    "#     df = df.drop(['article_link'], axis=1)\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         data.append({'label': row['is_sarcastic'], 'sent':row['headline']})\n",
    "#     random.shuffle(data)\n",
    "#     train = data[:int(len(data)*0.8)]\n",
    "#     dev = data[int(len(data)*0.8):int(len(data)*0.9)]\n",
    "#     test = data[int(len(data)*0.9):]\n",
    "      \n",
    "#     return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "O2aj9jC_p-C7",
    "outputId": "0c789ac6-f59d-40a4-b870-9a0bc6e349ca"
   },
   "outputs": [],
   "source": [
    "# train_dat, dev_dat, test_dat = load_data(dat_dir)\n",
    "\n",
    "# # Sanity check on the train, dev, and test sets\n",
    "# print('Number of sentences in Train')\n",
    "# count = {}\n",
    "# count[0] = 0\n",
    "# count[1] = 0\n",
    "# for d in train_dat:\n",
    "#     count[d['label']] += 1\n",
    "# for key,val in count.items():\n",
    "#     print(key, val)\n",
    "# print('Total: ', len(train_dat))\n",
    "\n",
    "# print()\n",
    "# print('Number of sentences in Dev')\n",
    "# count = {}\n",
    "# count[0] = 0\n",
    "# count[1] = 0\n",
    "# for d in dev_dat:\n",
    "#     count[d['label']] += 1\n",
    "# for key,val in count.items():\n",
    "#     print(key, val)\n",
    "# print('Total: ', len(dev_dat))\n",
    "\n",
    "# print()\n",
    "# print('Number of sentences in Test')\n",
    "# count = {}\n",
    "# count[0] = 0\n",
    "# count[1] = 0\n",
    "# for d in test_dat:\n",
    "#     count[d['label']] += 1\n",
    "# for key,val in count.items():\n",
    "#     print(key, val)\n",
    "# print('Total: ', len(test_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe_pYoooLdYG"
   },
   "source": [
    "### Code to tokenize, train, and generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzyfFYBGMWCC"
   },
   "outputs": [],
   "source": [
    "# def tokenize_function(example):\n",
    "#   #the tokenizer is cached in memory, so will not re-download for every function call. \n",
    "#   tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\",\n",
    "#                                                       truncation=True,\n",
    "#                                                       do_lower_case=True)\n",
    "#   tokenized = tokenizer(example['sent'],\n",
    "#                         padding = 'max_length',\n",
    "#                         return_tensors='pt') #returns dict\n",
    "#   # convert label to a tensor and add it to the tokenized.\n",
    "#   lab = example['label']\n",
    "#   tokenized['labels'] = torch.tensor(int(lab)).to(device)\n",
    "\n",
    "#   return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vCSlCJkNPJx"
   },
   "outputs": [],
   "source": [
    "def train(model, tokenized_data, args):\n",
    "  num_epochs = args['num_epochs']\n",
    "  batch_size = args['batch_size']\n",
    "  lr = args['lr']\n",
    "  # Set up the optimizer\n",
    "  optimizer = AdamW(model.parameters())\n",
    "\n",
    "  # Set up a dataloader, which will divide the data into batches\n",
    "  train_dataloader = DataLoader(\n",
    "      tokenized_data, shuffle=True, batch_size=batch_size\n",
    "      )\n",
    "\n",
    "  num_training_steps = num_epochs * len(train_dataloader)\n",
    "  lr_scheduler = get_scheduler(\"linear\",\n",
    "                               optimizer=optimizer,\n",
    "                               num_warmup_steps=0,\n",
    "                               num_training_steps=num_training_steps,\n",
    "                               )\n",
    "  #Start train\n",
    "  progress_bar = tqdm(range(num_training_steps))\n",
    "  for epoch in range(num_epochs):\n",
    "    print(\"Epoch\",epoch)\n",
    "    for i,batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        input_ids = batch['input_ids'].squeeze()\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        #forward pass\n",
    "        outputs = model(input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        #compute loss and update weights\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "          \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        #progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcBCna1JNhdJ"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, tokenized_dataset, tokenizer, n):\n",
    "  \"\"\"\n",
    "  n: number of examples from the dataset you want predictions for\n",
    "  \"\"\"\n",
    "  preds = []\n",
    "  eval_dataset = DataLoader(tokenized_dataset[:n], batch_size=1, shuffle=False)\n",
    "  for i,batch in enumerate(eval_dataset):                \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    input_ids = batch['input_ids'].squeeze()\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['labels']\n",
    "    outputs = model(input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    best = torch.argmax(logits)\n",
    "    pred = best.item()\n",
    "\n",
    "    preds.append({'sent': tokenizer.decode(batch[\"input_ids\"][0][0]),\n",
    "                  'pred': pred,\n",
    "                  'gold': batch[\"labels\"][0].item(),\n",
    "                  'logits': outputs.logits})\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07TGj07uPBe6"
   },
   "source": [
    "## Evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miGulqrPP_S_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def make_confusion_matrix(predictions):\n",
    "    output_labels = []\n",
    "    gold_labels = []\n",
    "    for item in predictions:\n",
    "        output_labels.append(item['pred'])\n",
    "        gold_labels.append(item['gold'])\n",
    "    return np.array(confusion_matrix(gold_labels, output_labels, labels=list(set(gold_labels))))\n",
    "# Write a function to calculate accuracy\n",
    "def calc_accuracy(predictions, average_type='macro'):\n",
    "  cfm = make_confusion_matrix(predictions)\n",
    "  tp = np.array([cfm[i][i] for i in range(len(cfm))])\n",
    "  gold_size = np.sum(cfm,axis=1)\n",
    "  accuracies = np.divide(tp, gold_size)\n",
    "  \n",
    "  if average_type == 'macro':\n",
    "    return np.mean(accuracies)\n",
    "  else:\n",
    "    return np.sum(tp)/np.sum(gold_size)\n",
    "# Write a function to calculate precision\n",
    "def calc_precision(predictions, average_type='macro'):\n",
    "  cfm = make_confusion_matrix(predictions)\n",
    "  tp = np.array([cfm[i][i] for i in range(len(cfm))])\n",
    "  output_size = np.sum(cfm,axis=0)\n",
    "  precisions = []\n",
    "  for i in range(len(cfm)):\n",
    "    if output_size[i]==0:\n",
    "      precisions.append(0)\n",
    "    else:\n",
    "      precisions.append(tp[i]/ output_size[i])\n",
    "  \n",
    "  if average_type == 'macro':\n",
    "    return np.mean(precisions)\n",
    "  else:\n",
    "    return np.sum(tp)/np.sum(output_size)\n",
    "# Write a function to calculate recall\n",
    "def calc_recall(predictions, average_type='macro'):\n",
    "  cfm = make_confusion_matrix(predictions)\n",
    "  tp = np.array([cfm[i][i] for i in range(len(cfm))])\n",
    "  size = np.array([sum([cfm[i][j] for j in range(len(cfm))]) for i in range(len(cfm))])\n",
    "  recalls = np.divide(tp, size)\n",
    "  \n",
    "  if average_type == 'macro':\n",
    "    return np.mean(recalls)\n",
    "  else:\n",
    "    return np.sum(tp)/np.sum(size)\n",
    "# Write a function to calculate fscore\n",
    "def calc_fscore(precision, recall, beta):\n",
    "  beta = beta**2\n",
    "  return ((beta + 1)*precision*recall)/(beta*precision + recall)\n",
    "def print_scores(model_type, preds):\n",
    "  print(model_type)\n",
    "  print('-------------------------')\n",
    "  precision = calc_precision(preds, \"macro\")\n",
    "  recall = calc_recall(preds,  \"macro\")\n",
    "  accuracy = calc_accuracy(preds, \"micro\")\n",
    "  f1 = calc_fscore(precision, recall, 1)\n",
    "  f2 = calc_fscore(precision, recall, 2)\n",
    "  print('Precision\\t', round(precision, 3))\n",
    "  print('Recall\\t\\t', round(recall, 3))\n",
    "  print('Accuracy\\t', round(accuracy, 3))\n",
    "  print('F2\\t\\t', round(f2, 3))\n",
    "  print('F1\\t\\t', round(f1,3))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXwQ75vETJo6"
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Write your code here to load train, dev and test data. \n",
    "# train_dat, dev_dat, test_dat = load_data(dat_dir)\n",
    "\n",
    "# # Shuffle training, dev and test\n",
    "# random.shuffle(train_dat)\n",
    "# random.shuffle(dev_dat)\n",
    "# random.shuffle(test_dat)\n",
    "\n",
    "# # Create tokenized train, dev and test. \n",
    "# ## You might want to look at only a small subset of train, dev and test to avoid RAM issues. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GutlPhwBT-8V"
   },
   "source": [
    "## Fine-tuning the model\n",
    "\n",
    "Fine tune the model to the training dataset (or subsets of the dataset) and save it using `torch.save()`. Set the number of epochs to three, and the batch_size to 5. \n",
    "\n",
    "- Run on dev sets\n",
    "- With different training parameters\n",
    "- Choose argmax for hyperparameters combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mCsweiLcTjRL",
    "outputId": "6e1470f3-6b0e-4f01-fd24-b69209ca989b"
   },
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\",\n",
    "                                                            num_labels=2).to(device)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\",\n",
    "                                                      truncation=True,\n",
    "                                                      do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ4iWa0cTtZ-"
   },
   "source": [
    "Evaluate the model on the test set prior to fine-tuning. If you run into RAM issues, evaluate it on a smaller set using the n parameter of get_predictions(). Make sure to print precision, accuracy, recall and f1 in an easy to read format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnvBeIEPT2l8"
   },
   "outputs": [],
   "source": [
    "# # Write your code here\n",
    "# tokenized_train = [tokenize_function(e) for e in train_dat]\n",
    "# tokenized_test = [tokenize_function(t) for t in test_dat]\n",
    "# tokenized_dev = [tokenize_function(d) for d in dev_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the tokenized data into pickle files\n",
    "# with open('train_tokens.pickle', 'wb') as train:\n",
    "#     pickle.dump(tokenized_train, train, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# train.close()\n",
    "# with open('dev_tokens.pickle', 'wb') as dev:\n",
    "#     pickle.dump(tokenized_dev, dev, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# dev.close()\n",
    "# with open('test_tokens.pickle', 'wb') as test:\n",
    "#     pickle.dump(tokenized_test, test, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS TO LOAD TOKENIZED DATA\n",
    "with open('train_tokens.pickle', 'rb') as train:\n",
    "    tokenized_train = pickle.load(train)\n",
    "train.close()\n",
    "with open('dev_tokens.pickle', 'rb') as dev:\n",
    "    tokenized_dev = pickle.load(dev)\n",
    "dev.close()\n",
    "with open('test_tokens.pickle', 'rb') as test:\n",
    "    tokenized_test = pickle.load(test)\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 927/1431 [1:42:00<42:15,  5.03s/it]\u001b[A\n",
      " 65%|██████▍   | 928/1431 [1:42:05<42:28,  5.07s/it]\u001b[A\n",
      " 65%|██████▍   | 929/1431 [1:42:10<42:56,  5.13s/it]\u001b[A\n",
      " 65%|██████▍   | 930/1431 [1:42:16<45:49,  5.49s/it]\u001b[A\n",
      " 65%|██████▌   | 931/1431 [1:42:21<44:09,  5.30s/it]\u001b[A\n",
      " 65%|██████▌   | 932/1431 [1:42:26<42:48,  5.15s/it]\u001b[A\n",
      " 65%|██████▌   | 933/1431 [1:42:31<41:43,  5.03s/it]\u001b[A\n",
      " 65%|██████▌   | 934/1431 [1:42:36<41:18,  4.99s/it]\u001b[A\n",
      " 65%|██████▌   | 935/1431 [1:42:40<40:59,  4.96s/it]\u001b[A\n",
      " 65%|██████▌   | 936/1431 [1:42:46<41:05,  4.98s/it]\u001b[A\n",
      " 65%|██████▌   | 937/1431 [1:42:50<40:59,  4.98s/it]\u001b[A\n",
      " 66%|██████▌   | 938/1431 [1:42:56<42:09,  5.13s/it]\u001b[A\n",
      " 66%|██████▌   | 939/1431 [1:43:02<43:26,  5.30s/it]\u001b[A\n",
      " 66%|██████▌   | 940/1431 [1:43:07<42:23,  5.18s/it]\u001b[A\n",
      " 66%|██████▌   | 941/1431 [1:43:11<41:26,  5.07s/it]\u001b[A\n",
      " 66%|██████▌   | 942/1431 [1:43:16<40:47,  5.00s/it]\u001b[A\n",
      " 66%|██████▌   | 943/1431 [1:43:21<40:46,  5.01s/it]\u001b[A\n",
      " 66%|██████▌   | 944/1431 [1:43:26<41:11,  5.08s/it]\u001b[A\n",
      " 66%|██████▌   | 945/1431 [1:43:32<41:17,  5.10s/it]\u001b[A\n",
      " 66%|██████▌   | 946/1431 [1:43:37<40:58,  5.07s/it]\u001b[A\n",
      " 66%|██████▌   | 947/1431 [1:43:43<43:03,  5.34s/it]\u001b[A\n",
      " 66%|██████▌   | 948/1431 [1:43:47<41:49,  5.19s/it]\u001b[A\n",
      " 66%|██████▋   | 949/1431 [1:43:52<41:10,  5.13s/it]\u001b[A\n",
      " 66%|██████▋   | 950/1431 [1:43:58<41:03,  5.12s/it]\u001b[A\n",
      " 66%|██████▋   | 951/1431 [1:44:02<40:32,  5.07s/it]\u001b[A\n",
      " 67%|██████▋   | 952/1431 [1:44:07<40:07,  5.03s/it]\u001b[A\n",
      " 67%|██████▋   | 953/1431 [1:44:12<39:47,  5.00s/it]\u001b[A\n",
      " 67%|██████▋   | 954/1431 [1:44:17<40:02,  5.04s/it]\u001b[A\n",
      " 67%|██████▋   | 955/1431 [1:44:23<41:53,  5.28s/it]\u001b[A\n",
      " 67%|██████▋   | 956/1431 [1:44:29<41:55,  5.30s/it]\u001b[A\n",
      " 67%|██████▋   | 957/1431 [1:44:34<41:23,  5.24s/it]\u001b[A\n",
      " 67%|██████▋   | 958/1431 [1:44:39<40:09,  5.09s/it]\u001b[A\n",
      " 67%|██████▋   | 959/1431 [1:44:43<39:19,  5.00s/it]\u001b[A\n",
      " 67%|██████▋   | 960/1431 [1:44:48<38:59,  4.97s/it]\u001b[A\n",
      " 67%|██████▋   | 961/1431 [1:44:53<39:00,  4.98s/it]\u001b[A\n",
      " 67%|██████▋   | 962/1431 [1:44:58<38:48,  4.96s/it]\u001b[A\n",
      " 67%|██████▋   | 963/1431 [1:45:03<39:10,  5.02s/it]\u001b[A\n",
      " 67%|██████▋   | 964/1431 [1:45:09<41:19,  5.31s/it]\u001b[A\n",
      " 67%|██████▋   | 965/1431 [1:45:14<40:17,  5.19s/it]\u001b[A\n",
      " 68%|██████▊   | 966/1431 [1:45:19<39:12,  5.06s/it]\u001b[A\n",
      " 68%|██████▊   | 967/1431 [1:45:24<38:18,  4.95s/it]\u001b[A\n",
      " 68%|██████▊   | 968/1431 [1:45:29<38:02,  4.93s/it]\u001b[A\n",
      " 68%|██████▊   | 969/1431 [1:45:33<37:56,  4.93s/it]\u001b[A\n",
      " 68%|██████▊   | 970/1431 [1:45:38<38:09,  4.97s/it]\u001b[A\n",
      " 68%|██████▊   | 971/1431 [1:45:44<39:36,  5.17s/it]\u001b[A\n",
      " 68%|██████▊   | 972/1431 [1:45:50<41:22,  5.41s/it]\u001b[A\n",
      " 68%|██████▊   | 973/1431 [1:45:55<40:41,  5.33s/it]\u001b[A\n",
      " 68%|██████▊   | 974/1431 [1:46:00<39:39,  5.21s/it]\u001b[A\n",
      " 68%|██████▊   | 975/1431 [1:46:05<38:58,  5.13s/it]\u001b[A\n",
      " 68%|██████▊   | 976/1431 [1:46:10<38:29,  5.08s/it]\u001b[A\n",
      " 68%|██████▊   | 977/1431 [1:46:15<38:14,  5.05s/it]\u001b[A\n",
      " 68%|██████▊   | 978/1431 [1:46:20<37:30,  4.97s/it]\u001b[A\n",
      " 68%|██████▊   | 979/1431 [1:46:25<38:06,  5.06s/it]\u001b[A\n",
      " 68%|██████▊   | 980/1431 [1:46:31<39:40,  5.28s/it]\u001b[A\n",
      " 69%|██████▊   | 981/1431 [1:46:36<38:49,  5.18s/it]\u001b[A\n",
      " 69%|██████▊   | 982/1431 [1:46:41<38:12,  5.11s/it]\u001b[A\n",
      " 69%|██████▊   | 983/1431 [1:46:46<37:50,  5.07s/it]\u001b[A\n",
      " 69%|██████▉   | 984/1431 [1:46:51<37:18,  5.01s/it]\u001b[A\n",
      " 69%|██████▉   | 985/1431 [1:46:56<37:15,  5.01s/it]\u001b[A\n",
      " 69%|██████▉   | 986/1431 [1:47:00<36:35,  4.93s/it]\u001b[A\n",
      " 69%|██████▉   | 987/1431 [1:47:06<37:13,  5.03s/it]\u001b[A\n",
      " 69%|██████▉   | 988/1431 [1:47:12<40:05,  5.43s/it]\u001b[A\n",
      " 69%|██████▉   | 989/1431 [1:47:17<39:05,  5.31s/it]\u001b[A\n",
      " 69%|██████▉   | 990/1431 [1:47:22<38:07,  5.19s/it]\u001b[A\n",
      " 69%|██████▉   | 991/1431 [1:47:27<37:15,  5.08s/it]\u001b[A\n",
      " 69%|██████▉   | 992/1431 [1:47:32<36:53,  5.04s/it]\u001b[A\n",
      " 69%|██████▉   | 993/1431 [1:47:37<36:45,  5.04s/it]\u001b[A\n",
      " 69%|██████▉   | 994/1431 [1:47:42<36:20,  4.99s/it]\u001b[A\n",
      " 70%|██████▉   | 995/1431 [1:47:47<36:03,  4.96s/it]\u001b[A\n",
      " 70%|██████▉   | 996/1431 [1:47:52<37:35,  5.19s/it]\u001b[A\n",
      " 70%|██████▉   | 997/1431 [1:47:57<37:24,  5.17s/it]\u001b[A\n",
      " 70%|██████▉   | 998/1431 [1:48:02<36:23,  5.04s/it]\u001b[A\n",
      " 70%|██████▉   | 999/1431 [1:48:07<36:30,  5.07s/it]\u001b[A\n",
      " 70%|██████▉   | 1000/1431 [1:48:12<35:36,  4.96s/it]\u001b[A\n",
      " 70%|██████▉   | 1001/1431 [1:48:17<35:15,  4.92s/it]\u001b[A\n",
      " 70%|███████   | 1002/1431 [1:48:22<35:03,  4.90s/it]\u001b[A\n",
      " 70%|███████   | 1003/1431 [1:48:26<34:47,  4.88s/it]\u001b[A\n",
      " 70%|███████   | 1004/1431 [1:48:33<37:44,  5.30s/it]\u001b[A\n",
      " 70%|███████   | 1005/1431 [1:48:38<37:20,  5.26s/it]\u001b[A\n",
      " 70%|███████   | 1006/1431 [1:48:43<36:17,  5.12s/it]\u001b[A\n",
      " 70%|███████   | 1007/1431 [1:48:48<35:50,  5.07s/it]\u001b[A\n",
      " 70%|███████   | 1008/1431 [1:48:53<35:25,  5.03s/it]\u001b[A\n",
      " 71%|███████   | 1009/1431 [1:48:58<35:14,  5.01s/it]\u001b[A\n",
      " 71%|███████   | 1010/1431 [1:49:02<35:01,  4.99s/it]\u001b[A\n",
      " 71%|███████   | 1011/1431 [1:49:07<34:57,  4.99s/it]\u001b[A\n",
      " 71%|███████   | 1012/1431 [1:49:14<37:11,  5.32s/it]\u001b[A\n",
      " 71%|███████   | 1013/1431 [1:49:19<36:54,  5.30s/it]\u001b[A\n",
      " 71%|███████   | 1014/1431 [1:49:24<36:06,  5.19s/it]\u001b[A\n",
      " 71%|███████   | 1015/1431 [1:49:29<35:22,  5.10s/it]\u001b[A\n",
      " 71%|███████   | 1016/1431 [1:49:34<35:04,  5.07s/it]\u001b[A\n",
      " 71%|███████   | 1017/1431 [1:49:39<34:39,  5.02s/it]\u001b[A\n",
      " 71%|███████   | 1018/1431 [1:49:44<34:36,  5.03s/it]\u001b[A\n",
      " 71%|███████   | 1019/1431 [1:49:49<34:54,  5.08s/it]\u001b[A\n",
      " 71%|███████▏  | 1020/1431 [1:49:55<36:35,  5.34s/it]\u001b[A\n",
      " 71%|███████▏  | 1021/1431 [1:50:00<36:30,  5.34s/it]\u001b[A\n",
      " 71%|███████▏  | 1022/1431 [1:50:05<35:48,  5.25s/it]\u001b[A\n",
      " 71%|███████▏  | 1023/1431 [1:50:10<35:03,  5.15s/it]\u001b[A\n",
      " 72%|███████▏  | 1024/1431 [1:50:15<34:34,  5.10s/it]\u001b[A\n",
      " 72%|███████▏  | 1025/1431 [1:50:20<34:10,  5.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1026/1431 [1:50:25<33:31,  4.97s/it]\u001b[A\n",
      " 72%|███████▏  | 1027/1431 [1:50:30<33:08,  4.92s/it]\u001b[A\n",
      " 72%|███████▏  | 1028/1431 [1:50:35<34:01,  5.07s/it]\u001b[A\n",
      " 72%|███████▏  | 1029/1431 [1:50:41<35:26,  5.29s/it]\u001b[A\n",
      " 72%|███████▏  | 1030/1431 [1:50:46<34:58,  5.23s/it]\u001b[A\n",
      " 72%|███████▏  | 1031/1431 [1:50:51<34:26,  5.17s/it]\u001b[A\n",
      " 72%|███████▏  | 1032/1431 [1:50:56<33:38,  5.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1033/1431 [1:51:00<32:56,  4.97s/it]\u001b[A\n",
      " 72%|███████▏  | 1034/1431 [1:51:05<32:33,  4.92s/it]\u001b[A\n",
      " 72%|███████▏  | 1035/1431 [1:51:10<32:43,  4.96s/it]\u001b[A\n",
      " 72%|███████▏  | 1036/1431 [1:51:16<33:21,  5.07s/it]\u001b[A\n",
      " 72%|███████▏  | 1037/1431 [1:51:22<35:05,  5.34s/it]\u001b[A\n",
      " 73%|███████▎  | 1038/1431 [1:51:27<34:18,  5.24s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# MODIFY THIS!\n",
    "args = {\n",
    "    'num_epochs': 4,\n",
    "    'batch_size': 16,\n",
    "    'lr' : 3e-5\n",
    "}\n",
    "\n",
    "## Write your code here\n",
    "train(model, tokenized_train, args)\n",
    "torch.save(model, 'model8.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "a83b9eb3a66549a9a961c431096af6d8",
      "f198ab5190ba45239ce5641e9a77ec7f",
      "d36c6042b96043d798db9623b23c1198",
      "a976188f154445e79a020b4dfc3926c2",
      "1fdbda1cf34f4783b000088aeede62d9",
      "b6ba4d9649814537924e52b474be9d04",
      "ea070d4b5cfc4eef88de19b90a182372",
      "30197bda610b485d9511bb617109a779",
      "15c32d8080ac45c7a7461e6e4f2d1966",
      "b9d004955940435cbec8186500504658",
      "3dfbdee902b54968a08974f03343f807",
      "76161372e19e42edb08fb885638bf152",
      "6e97f94176664de185f48eec628b64ca",
      "ec20de5274c445d88a0ede6cf40972ea",
      "c11750b7611247b99e32fc99eee3ea06",
      "e603e66e48874967992f17946be34917",
      "a813dea9dd754e96a3cac20c8245acd5",
      "fbf8989036e74a359d5d0e716a2b8c49",
      "e2e9d11f15ce4c238c7574056f791ff3",
      "0fd79f6d51c54dd08f4379a1b27b071a",
      "44e790e9a3a5474d823740e27fa1f165",
      "9f28e78628534199b4f349844ca6214d"
     ]
    },
    "id": "5uL_rbwmW44D",
    "outputId": "1eafc886-e156-47eb-f726-0029ab7824c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 4,\n",
    "    'batch_size': 16,\n",
    "    'lr' : 3e-4\n",
    "}\n",
    "\n",
    "## Write your code here\n",
    "train(model, tokenized_train, args)\n",
    "torch.save(model, 'model9.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oz4rJZ9FXbdp"
   },
   "source": [
    "## Evaluating the model\n",
    "\n",
    "Evaluate the saved model on the test set. Make sure to display the evaluation metrics in an easy-to-view format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwllbAR9Xkx8"
   },
   "outputs": [],
   "source": [
    "trained_model8 = torch.load('model8.pt')\n",
    "preds8 = get_predictions(trained_model8, tokenized_dev, tokenizer, len(tokenized_dev))\n",
    "print_scores(\"model after fine-tuning yields these scores\", preds8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model9 = torch.load('model9.pt')\n",
    "preds9 = get_predictions(trained_model9, tokenized_dev, tokenizer, len(tokenized_dev))\n",
    "print_scores(\"model after fine-tuning yields these scores\", preds9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model for Sequence Classification\n",
    "\n",
    "- This class is defined to accept the `tokenizer`, `dataframe` and `max_length` as input and generate tokenized output and tags that is used by the BERT model for training. \n",
    "- We are using the BERT tokenizer to tokenize the data in the `comment_text` column of the dataframe.\n",
    "- The tokenizer uses the `encode_plus` method to perform tokenization and generate the necessary outputs, namely: `ids`, `attention_mask`, `token_type_ids`\n",
    "---\n",
    "- *This is the first difference between the distilbert and bert, where the tokenizer generates the token_type_ids in case of Bert*\n",
    "---\n",
    "- To read further into the tokenizer, [refer to this document](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer)\n",
    "- *It is to be noted that the overall mechanisms for a multiclass and multilabel problems are similar, except for few differences namely:*\n",
    "\t- *Loss function is designed to evaluate all the probability of categories individually rather than as compared to other categories. Hence the use of `BCE` rather than `Cross Entropy` when defining loss.*\n",
    "\t- *Sigmoid of the outputs calcuated to rather than Softmax. Again for the reasons defined in the previous point*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bert_function(example):\n",
    "  #the tokenizer is cached in memory, so will not re-download for every function call. \n",
    "  tokenizer_bert = BertTokenizerFast.from_pretrained('bert-base-uncased',\n",
    "                                                      truncation=True,\n",
    "                                                      do_lower_case=True)\n",
    "  tokenized = tokenizer_bert(example['sent'],\n",
    "                        padding = 'max_length',\n",
    "                        return_tensors='pt') #returns dict\n",
    "  # convert label to a tensor and add it to the tokenized.\n",
    "  lab = example['label']\n",
    "  tokenized['labels'] = torch.tensor(int(lab)).to(device)\n",
    "\n",
    "  return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizerFast.from_pretrained('bert-base-uncased',\n",
    "                                                      truncation=True,\n",
    "                                                      do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_train(model, tokenized_data, args):\n",
    "  num_epochs = args['num_epochs']\n",
    "  batch_size = args['batch_size']\n",
    "  lr = args['lr']\n",
    "  # Set up the optimizer\n",
    "  optimizer = AdamW(model.parameters())\n",
    "\n",
    "  # Set up a dataloader, which will divide the data into batches\n",
    "  train_dataloader = DataLoader(\n",
    "      tokenized_data, shuffle=True, batch_size=batch_size\n",
    "      )\n",
    "\n",
    "  num_training_steps = num_epochs * len(train_dataloader)\n",
    "  lr_scheduler = get_scheduler(\"linear\",\n",
    "                               optimizer=optimizer,\n",
    "                               num_warmup_steps=0,\n",
    "                               num_training_steps=num_training_steps,\n",
    "                               )\n",
    "  #Start train\n",
    "  progress_bar = tqdm(range(num_training_steps))\n",
    "  for epoch in range(num_epochs):\n",
    "    print(\"Epoch\",epoch)\n",
    "    for i,batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        input_ids = batch['input_ids'].squeeze()\n",
    "        attention_mask = batch['attention_mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        labels = batch['labels']\n",
    "        #forward pass\n",
    "        outputs = model(input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels)\n",
    "        #compute loss and update weights\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "          \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        #progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "bert_tokenized_train = [tokenize_bert_function(e) for e in train_dat]\n",
    "bert_tokenized_test = [tokenize_bert_function(t) for t in test_dat]\n",
    "bert_tokenized_dev = [tokenize_bert_function(d) for d in dev_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenized data into pickle files\n",
    "with open('bert_train_tokens.pickle', 'wb') as train:\n",
    "    pickle.dump(tokenized_train, train, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "train.close()\n",
    "with open('bert_dev_tokens.pickle', 'wb') as dev:\n",
    "    pickle.dump(tokenized_dev, dev, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "dev.close()\n",
    "with open('bert_test_tokens.pickle', 'wb') as test:\n",
    "    pickle.dump(tokenized_test, test, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network. \n",
    "\n",
    "Following events happen in this function to fine tune the neural network:\n",
    "- The dataloader passes data to the model based on the batch size. \n",
    "- Subsequent output from the model and the actual category are compared to calculate the loss. \n",
    "- Loss value is used to optimize the weights of the neurons in the network.\n",
    "- After every 5000 steps the loss value is printed in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_bert(model, tokenized_dataset, tokenizer, n):\n",
    "  \"\"\"\n",
    "  n: number of examples from the dataset you want predictions for\n",
    "  \"\"\"\n",
    "  preds = []\n",
    "  eval_dataset = DataLoader(tokenized_dataset[:n], batch_size=1, shuffle=False)\n",
    "  for i,batch in enumerate(eval_dataset):                \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    input_ids = batch['input_ids'].squeeze()\n",
    "    input_shape = input_ids.size()\n",
    "    print(\"SHAPE: \", input_shape)\n",
    "    attention_mask = batch['attention_mask']\n",
    "    token_type_ids = batch['token_type_ids']\n",
    "    labels = batch['labels']\n",
    "    outputs = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    labels=labels)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    best = torch.argmax(logits)\n",
    "    pred = best.item()\n",
    "\n",
    "    preds.append({'pred': pred,\n",
    "                  'gold': batch[\"labels\"][0].item()})\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtJQahxo5wj8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'num_epochs': 4,\n",
    "    'batch_size': 16,\n",
    "    'lr' : 3e-5\n",
    "}\n",
    "\n",
    "## Write your code here\n",
    "train(model_bert,bert_tokenized_train, args)\n",
    "torch.save(model_bert, 'model_bert.pt')\n",
    "trained_model_bert = torch.load('model_bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trained_model = torch.load('model_bert.pt')\n",
    "bert_preds = get_predictions_bert(bert_trained_model, bert_tokenized_test, tokenizer_bert, 300)\n",
    "print_scores(\"model after fine-tuning yields these scores\", bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trained_model = torch.load('model_bert.pt')\n",
    "bert_preds = get_predictions(bert_trained_model, bert_tokenized_test, tokenizer_bert, 300)\n",
    "print_scores(\"model after fine-tuning yields these scores\", bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ce98c6d44ce4b5eaefbaefda1f8c40d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5511718847614a99bd1d7c9d953af417",
      "placeholder": "​",
      "style": "IPY_MODEL_2a33f8b764f244bca99f0fb3c76e1566",
      "value": " 436M/436M [00:07&lt;00:00, 69.4MB/s]"
     }
    },
    "0fd79f6d51c54dd08f4379a1b27b071a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15c32d8080ac45c7a7461e6e4f2d1966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f5683e8ea4f4aaf805088be4b1e08fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fdbda1cf34f4783b000088aeede62d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28623378d85b40e594dcbf3544cf5f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f5683e8ea4f4aaf805088be4b1e08fd",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1225e4d72634955b328d44a92dcd1af",
      "value": 435779157
     }
    },
    "2a33f8b764f244bca99f0fb3c76e1566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30197bda610b485d9511bb617109a779": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dfbdee902b54968a08974f03343f807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44e790e9a3a5474d823740e27fa1f165": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5511718847614a99bd1d7c9d953af417": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c619346812643f082450c93f03d9963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_931d38de5cd7496bade0cf700cc35dca",
      "placeholder": "​",
      "style": "IPY_MODEL_91b6251c0b104c5b9f25644fcd850a87",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "6e97f94176664de185f48eec628b64ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a813dea9dd754e96a3cac20c8245acd5",
      "placeholder": "​",
      "style": "IPY_MODEL_fbf8989036e74a359d5d0e716a2b8c49",
      "value": " 30%"
     }
    },
    "727f897bc98a4de9a44b0308743045ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76161372e19e42edb08fb885638bf152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e97f94176664de185f48eec628b64ca",
       "IPY_MODEL_ec20de5274c445d88a0ede6cf40972ea",
       "IPY_MODEL_c11750b7611247b99e32fc99eee3ea06"
      ],
      "layout": "IPY_MODEL_e603e66e48874967992f17946be34917"
     }
    },
    "91b6251c0b104c5b9f25644fcd850a87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "931d38de5cd7496bade0cf700cc35dca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f28e78628534199b4f349844ca6214d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a813dea9dd754e96a3cac20c8245acd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a83b9eb3a66549a9a961c431096af6d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f198ab5190ba45239ce5641e9a77ec7f",
       "IPY_MODEL_d36c6042b96043d798db9623b23c1198",
       "IPY_MODEL_a976188f154445e79a020b4dfc3926c2"
      ],
      "layout": "IPY_MODEL_1fdbda1cf34f4783b000088aeede62d9"
     }
    },
    "a976188f154445e79a020b4dfc3926c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9d004955940435cbec8186500504658",
      "placeholder": "​",
      "style": "IPY_MODEL_3dfbdee902b54968a08974f03343f807",
      "value": " 6/60 [01:40&lt;14:54, 16.56s/it]"
     }
    },
    "b6ba4d9649814537924e52b474be9d04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8a7e046fc8e4040b8e6a0466e54c409": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c619346812643f082450c93f03d9963",
       "IPY_MODEL_28623378d85b40e594dcbf3544cf5f8d",
       "IPY_MODEL_0ce98c6d44ce4b5eaefbaefda1f8c40d"
      ],
      "layout": "IPY_MODEL_727f897bc98a4de9a44b0308743045ff"
     }
    },
    "b9d004955940435cbec8186500504658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c11750b7611247b99e32fc99eee3ea06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44e790e9a3a5474d823740e27fa1f165",
      "placeholder": "​",
      "style": "IPY_MODEL_9f28e78628534199b4f349844ca6214d",
      "value": " 6/20 [01:40&lt;03:51, 16.56s/it]"
     }
    },
    "d36c6042b96043d798db9623b23c1198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30197bda610b485d9511bb617109a779",
      "max": 60,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15c32d8080ac45c7a7461e6e4f2d1966",
      "value": 6
     }
    },
    "e1225e4d72634955b328d44a92dcd1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2e9d11f15ce4c238c7574056f791ff3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e603e66e48874967992f17946be34917": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea070d4b5cfc4eef88de19b90a182372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec20de5274c445d88a0ede6cf40972ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2e9d11f15ce4c238c7574056f791ff3",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fd79f6d51c54dd08f4379a1b27b071a",
      "value": 6
     }
    },
    "f198ab5190ba45239ce5641e9a77ec7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ba4d9649814537924e52b474be9d04",
      "placeholder": "​",
      "style": "IPY_MODEL_ea070d4b5cfc4eef88de19b90a182372",
      "value": " 10%"
     }
    },
    "fbf8989036e74a359d5d0e716a2b8c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
